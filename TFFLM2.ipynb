{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "from Bio import Seq\n",
    "from Bio.Seq import Seq\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.SeqFeature import FeatureLocation, CompoundLocation\n",
    "import networkx as nx\n",
    "from random import choice\n",
    "\n",
    "sys.path.append(\"../../..\")\n",
    "from gene_utils import *\n",
    "from TFFamily import *\n",
    "\n",
    "motif_path = Path('/home/sc2/Documents/deepbind-motif-data/encode-deepbind') # ChIP-seq datasets\n",
    "path = Path('language_models_data') # hg38 datasets and language models\n",
    "\n",
    "\n",
    "# motif_f_list_path = 'TF_CellLine.txt'\n",
    "# tf_family_name = 'ATF2'\n",
    "\n",
    "\n",
    "# # LM Fine Tune\n",
    "\n",
    "# Here we create a language model corpus from our classification dataset. This basically concatenates all our promoter sequences into a single long string of text. The language model is trained on the concatenated promoter corpus. We need to make sure to create our dataloader with the correct vocabulary.\n",
    "\n",
    "\n",
    "def motif_family_init(motif_path):\n",
    "    list_f = os.listdir(motif_path)\n",
    "    list_f = sorted(list_f)\n",
    "    ptf = list_f[0].split('_')[0]\n",
    "    motif_family_dict = {}\n",
    "    motif_family_list = []\n",
    "    for i in range(len(list_f)):\n",
    "        f_name = list_f[i]\n",
    "        tf = f_name.split('_')[0]\n",
    "        # print(f_name)\n",
    "        if tf == ptf:\n",
    "            # print(i)\n",
    "            motif_family_list.append(f_name)\n",
    "        else:\n",
    "            motif_family_dict[ptf] = motif_family_list\n",
    "            motif_family_list = []\n",
    "            motif_family_list.append(f_name)\n",
    "            # print(i)\n",
    "        ptf = f_name.split('_')[0]\n",
    "    return motif_family_dict\n",
    "\n",
    "\n",
    "def clear_map(x):\n",
    "    if (x.find('N')!=-1) or (x.find('n')!=-1):\n",
    "        print(x)\n",
    "        x = None\n",
    "\n",
    "    return x\n",
    "\n",
    "def gen_negetive_by_random(len_neg, len_neg_df):\n",
    "    data = {}\n",
    "    random_seq = []\n",
    "    for j in range(len_neg_df):\n",
    "              \n",
    "        random_word = ''\n",
    "        for i in range(len_neg):\n",
    "            random_w = choice(['A','T','C','G'])\n",
    "            random_word += random_w\n",
    "        random_seq.append(random_word)\n",
    "    data = ({'seq':Series(random_seq)})\n",
    "    \n",
    "    df = DataFrame(data)\n",
    "    df.insert(df.shape[1],'Bound',0)\n",
    "    return df\n",
    "\n",
    "def gen_negetive_by_shuffle(len_neg, target_df):\n",
    "    data = {}\n",
    "    random_seq = []\n",
    "    print(len(target_df))\n",
    "    for index, row in target_df.iterrows():\n",
    "        target_seq = row['seq']\n",
    "\n",
    "        random_word = dinucshuffle(target_seq)\n",
    "        random_seq.append(random_word)\n",
    "    data = ({'seq':Series(random_seq)})\n",
    "    \n",
    "    df = DataFrame(data)\n",
    "    df.insert(df.shape[1],'Bound',0)\n",
    "    return df\n",
    "\n",
    "def dinucshuffle(sequence):\n",
    "    b=[sequence[i:i+2] for i in range(0, len(sequence), 2)]\n",
    "    random.shuffle(b)\n",
    "    d=''.join([str(x) for x in b])\n",
    "    return d\n",
    "\n",
    "def write_list(res_socre_list,res_path='res_deepbind_all_score_temp.txt'):\n",
    "    wf = open(res_path,'w')\n",
    "    for i in range(len(res_socre_list)):\n",
    "        for j in range(len(res_socre_list[i])):\n",
    "            wf.write(str(res_socre_list[i][j]))\n",
    "            wf.write(',')\n",
    "        wf.write('\\n')\n",
    "    wf.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classfication(train_l,test_l,encoder_name = 'human_5m1s_enc2-286'):\n",
    "\n",
    "    res_score_list = []\n",
    "    # for k in motif_family_dict:\n",
    "        # try:\n",
    "    if True:    \n",
    "            # motif_family_path_l = motif_family_dict[k]\n",
    "            # train_l = motif_family_path_l[::2]\n",
    "            # test_l = motif_family_path_l[1::2]\n",
    "\n",
    "\n",
    "            for i in range(len(train_l)):\n",
    "                    print('motif:',train_l[i])\n",
    "                    train_df = pd.read_csv(motif_path/train_l[i],sep='\\t',compression='gzip', error_bad_lines=False)\n",
    "                    train_df.seq = train_df.seq.map(clear_map)\n",
    "                    train_df.dropna(axis=0,how='any',inplace=True)\n",
    "                    if len(train_df) < 1000:\n",
    "                        print('too smalll',len(train_df))\n",
    "                        continue\n",
    "                    # print(train_df.head())\n",
    "                    len_val = int(len(train_df)*0.3)\n",
    "                    train_df = train_df[len_val:]\n",
    "                    valid_df = train_df[0:len_val]\n",
    "                    # print(train_df.head())\n",
    "                    test_df = pd.read_csv(motif_path/test_l[i],sep='\\t',compression='gzip', error_bad_lines=False)\n",
    "                    test_df.seq = test_df.seq.map(clear_map)\n",
    "                    test_df.dropna(axis=0,how='any',inplace=True)\n",
    "\n",
    "                    len_seq = 101#len(train_df.loc[0]['seq'])\n",
    "                    train_df.drop(['FoldID','EventID'], axis = 1, inplace = True)\n",
    "                    valid_df.drop(['FoldID','EventID'], axis = 1, inplace = True)\n",
    "                    test_df.drop(['FoldID','EventID'], axis = 1, inplace = True)\n",
    "\n",
    "                    df_neg = gen_negetive_by_shuffle(len_seq,train_df)\n",
    "                    train_df = train_df.append(df_neg, ignore_index=True)\n",
    "                    df_neg = gen_negetive_by_shuffle(len_seq,valid_df)\n",
    "                    valid_df = valid_df.append(df_neg, ignore_index=True)\n",
    "                    df_neg = gen_negetive_by_shuffle(len_seq,test_df)\n",
    "                    test_df = test_df.append(df_neg, ignore_index=True)\n",
    "\n",
    "                    voc = np.load(path/'human_vocab_5m1s.npy')\n",
    "                    model_vocab = GenomicVocab(voc)\n",
    "                    tok = Tokenizer(partial(GenomicTokenizer, ngram=5, stride=1), n_cpus=1, pre_rules=[], post_rules=[], special_cases=['xxpad'])\n",
    "                    data_clas = GenomicTextClasDataBunch.from_df(path, train_df, valid_df, tokenizer=tok, vocab=model_vocab, min_freq = 100,\n",
    "                                                                text_cols='seq', label_cols='Bound', bs=400)\n",
    "                    clas_config = dict(emb_sz=200, n_hid=800, n_layers=6, pad_token=0, qrnn=False, output_p=0.4, \n",
    "                                       hidden_p=0.2, input_p=0.6, embed_p=0.1, weight_p=0.5)\n",
    "                    drop_mult = 0.25\n",
    "                    learn = get_model_clas(data_clas, drop_mult, clas_config)\n",
    "                    #learn = get_model_clas(data_clas, drop_mult, clas_config)\n",
    "                    \n",
    "                    \n",
    "                    learn.load_encoder(encoder_name)\n",
    "                    \n",
    "                    learn = learn.to_fp16(dynamic=True);\n",
    "                    learn.freeze()\n",
    "                    try:\n",
    "                        learn.lr_find()\n",
    "                    except:\n",
    "                        print('continue',train_l[i])\n",
    "                        continue\n",
    "                    # learn.recorder.plot()\n",
    "                    learn.fit_one_cycle(3, 2e-2, moms=(0.8,0.7))\n",
    "                    learn.freeze_to(-2)\n",
    "                    learn.fit_one_cycle(3, slice(1e-2/(2.6**4),1e-2), moms=(0.8,0.7))\n",
    "                    learn.freeze_to(-3)\n",
    "                    learn.fit_one_cycle(3, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))\n",
    "                    learn.unfreeze()\n",
    "                    learn.fit_one_cycle(3, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))\n",
    "                    learn.fit_one_cycle(3, slice(1e-4/(2.6**4),1e-4), moms=(0.8,0.7))\n",
    "                    ft_name = 'human_motif_deepram_all_classification2_5m1s286'\n",
    "                    learn.save(ft_name)\n",
    "                    \n",
    "                    learn.data = data_clas\n",
    "                    res_score = get_scores(learn)\n",
    "                    res_score.append(train_l[i])\n",
    "                    res_score_list.append(res_score)\n",
    "            return res_score_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_l = []\n",
    "p_l = []\n",
    "def train_with_fine_tune(motif_family_dict):\n",
    "    trained_key = []\n",
    "    res_score_list = []\n",
    "    for k in motif_family_dict:\n",
    "        # try:\n",
    "        if True:    \n",
    "            if k in trained_key:\n",
    "                continue\n",
    "            '''\n",
    "            print('kkkkkkkkkkkkkkkkkkkkkkk', k)\n",
    "            brothers =  tff.find_brothers([k])\n",
    "            print('brother',brothers)\n",
    "            if len(brothers) == 0:\n",
    "                brothers.append([k])\n",
    "            motif_family_path_l = motif_family_dict[k]\n",
    "\n",
    "            for brother_k in brothers[0]:\n",
    "                # print(brother_k,type(brother_k))\n",
    "                if not(brother_k in motif_family_dict.keys()):\n",
    "                    continue\n",
    "                print(brother_k)\n",
    "                trained_key.append(brother_k)\n",
    "                motif_family_path_l = motif_family_dict[brother_k]\n",
    "\n",
    "                if k != brother_k:\n",
    "                    print(brother_k,type(brother_k))\n",
    "                    train_l.extend(motif_family_path_l[::2])\n",
    "                    test_l.extend(motif_family_path_l[1::2])\n",
    "                    Fine_Tune_df = pd.read_csv(motif_path/train_l[0],sep='\\t',compression='gzip', error_bad_lines=False)\n",
    "            '''\n",
    "            motif_family_path_l = motif_family_dict[k]\n",
    "            train_l = motif_family_path_l[::2]\n",
    "            test_l = motif_family_path_l[1::2]\n",
    "            Fine_Tune_df = pd.read_csv(motif_path/train_l[0],sep='\\t',compression='gzip', error_bad_lines=False)\n",
    "            if 1:\n",
    "                for motif_p in train_l:\n",
    "                    tm_df = pd.read_csv(motif_path/motif_p,sep='\\t',compression='gzip', error_bad_lines=False)\n",
    "                    Fine_Tune_df = Fine_Tune_df.append(tm_df)\n",
    "\n",
    "                Fine_Tune_df.drop(['FoldID','EventID'], axis = 1, inplace = True)\n",
    "                #print('brothers',len(Fine_Tune_df), len(train_l))\n",
    "            rorder = np.random.permutation(len(Fine_Tune_df))\n",
    "            Fine_Tune_df = Fine_Tune_df.take(rorder)\n",
    "            len_val = int(len(Fine_Tune_df)*0.3)\n",
    "            tf_train_df = Fine_Tune_df[len_val:]\n",
    "            tf_valid_df = Fine_Tune_df[0:len_val]\n",
    "\n",
    "\n",
    "\n",
    "            tf_train_df.seq = tf_train_df.seq.map(clear_map)\n",
    "            tf_train_df.dropna(axis=0,how='any',inplace=True)\n",
    "\n",
    "            tf_valid_df.seq = tf_valid_df.seq.map(clear_map)\n",
    "            tf_valid_df.dropna(axis=0,how='any',inplace=True)\n",
    "\n",
    "            voc = np.load(path/'human_vocab_5m1s.npy')\n",
    "            model_vocab = GenomicVocab(voc)\n",
    "            len_seq = 101 #len(tf_valid_df.loc[0]['seq'])\n",
    "\n",
    "            df_neg = gen_negetive_by_shuffle(len_seq,tf_train_df)\n",
    "            tf_train_df = tf_train_df.append(df_neg, ignore_index=True)\n",
    "\n",
    "            df_neg = gen_negetive_by_shuffle(len_seq,tf_valid_df)\n",
    "            tf_valid_df = tf_valid_df.append(df_neg, ignore_index=True)\n",
    "\n",
    "            tok = Tokenizer(partial(GenomicTokenizer, ngram=5, stride=1), n_cpus=1, pre_rules=[], post_rules=[], special_cases=['xxpad'])\n",
    "            data = GenomicTextLMDataBunch.from_df(path, tf_train_df, tf_valid_df, bs=800, tokenizer=tok, \n",
    "                                              chunksize=10000, text_cols='seq', label_cols='Bound', vocab=model_vocab, min_freq=100)\n",
    "            config = dict(emb_sz=200, n_hid=800, n_layers=6, pad_token=0, qrnn=False, output_p=0.25, \n",
    "                                          hidden_p=0.1, input_p=0.2, embed_p=0.02, weight_p=0.15, tie_weights=True, out_bias=True)\n",
    "            drop_mult = 0.5\n",
    "            learn = get_model_LM(data, drop_mult, config)\n",
    "            \n",
    "            #brothers_name = ''\n",
    "            #for i in range(len(brothers[0])):\n",
    "            #    brothers_name = brothers_name + brothers[0][i]\n",
    "            tf_family_learn_name = 'human_motif_deepbind2'+ k +'_5m1s-286'\n",
    "            tf_family_encoder_name = 'human_motif_deepbind2'+ k +'_5m1s_enc-286'\n",
    "            \n",
    "            if os.path.exists('../human_data/models/'+tf_family_encoder_name+'.pth') == False:\n",
    "                print('no finetune, start finetune')\n",
    "                learn = learn.to_fp16(dynamic=True);\n",
    "                learn.load('human_5m1s2-286');\n",
    "                learn.lr_find()\n",
    "                learn.recorder.plot()\n",
    "                learn.fit_one_cycle(10, 1e-2, moms=(0.8,0.7))\n",
    "            \n",
    "                learn.save(tf_family_learn_name)\n",
    "                learn.save_encoder(tf_family_encoder_name)\n",
    "            learn.load(tf_family_learn_name)\n",
    "            learn.load_encoder(tf_family_encoder_name)\n",
    "\n",
    "            tf_score = classfication(train_l,test_l,tf_family_encoder_name)\n",
    "            res_score_list.extend(tf_score)\n",
    "\n",
    "    write_list(res_score_list,'res.txt')\n",
    "    return res_score_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main_pre():\n",
    "    \n",
    "    \n",
    "    motif_family_dict = {}\n",
    "    motif_family_dict = motif_family_init(motif_path)\n",
    "    # tff = TFFamily('../../../tree')\n",
    "    \n",
    "    test_dict = {}\n",
    "    # print(motif_family_dict['BATF'])\n",
    "    test_dict['ELK4'] = motif_family_dict['ELK4']\n",
    "    for k in motif_family_dict:\n",
    "        train_list = motif_family_dict[k][::2]\n",
    "        test_list = motif_family_dict[k][1::2]\n",
    "        temp_score_list = train_with_pre_training(train_list, test_list)\n",
    "        res_score_list.extend(temp_score_list)\n",
    "        \n",
    "    write_list(res_score_list,'2_family_temp.txt')\n",
    "    print(res_score_list)\n",
    "    \n",
    "def main():\n",
    "\n",
    "    tfs_df = pd.read_csv('~/Documents/deepbind-motif-data/TF_CellLine.txt',header=None)\n",
    "    tf = tfs_df[0].map(lambda x : x.split('_')[0])\n",
    "    tf_k = sorted(list(set(tf)))\n",
    "\n",
    "    motif_family_dict = {}\n",
    "    motif_family_dict = motif_family_init(motif_path)\n",
    "    # tff = TFFamily('../../../tree')\n",
    "\n",
    "    test_dict = {}\n",
    "    # print(motif_family_dict['BATF'])\n",
    "    for k in tf_k:\n",
    "        test_dict[k] = motif_family_dict[k]\n",
    "\n",
    "    # test_dict['TCF3'] = motif_family_dict['TCF3']\n",
    "    res_score_list = train_with_fine_tune(test_dict)\n",
    "    # res_score_list = train_with_fine_tune(test_dict, tff)\n",
    "    print(res_score_list)\n",
    "    write_list(res_score_list, '69fine5m.txt')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9977759648816114\n",
      "Accuracy: 0.9688295165394402\n",
      "False Positives: 0.02989821882951654\n",
      "False Negatives: 0.001272264631043257\n",
      "MCC: 0.939199541691056\n",
      "Recall: 0.9974554707379135\n",
      "Precision: 0.9434416365824309\n",
      "Specificity: 0.9402035623409669\n",
      "motif: BHLHE40_GM12878_BHLHE40_(NB100-1800)_Stanford_AC.seq.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sc2/anaconda3/envs/ULMFiT/lib/python3.7/site-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9441\n",
      "4045\n",
      "1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='3', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      33.33% [1/3 00:16<00:32]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.680491</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='28' class='' max='47', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      59.57% [28/47 00:10<00:07 0.5453]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ULMFiT",
   "language": "python",
   "name": "ulmfit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
